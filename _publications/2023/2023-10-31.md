---
title: "Modular Boundaries in Recurrent Neural Networks"
collection: publications
permalink: /publication/2023-10-31
excerpt: "An article exploring whether modular structure meaningfully shapes neural dynamics by analyzing modular boundaries in recurrent neural networks using community-detection methods."
date: 2023-10-31
venue: "arXiv"
paperurl: 'https://doi.org/10.48550/arXiv.2310.20601'
citation: 'Tanner, Jacob, et al. &quot;Modular Boundaries in Recurrent Neural Networks.&quot; <i>arXiv preprint</i> (2023).'
---

[Article available from here.](https://doi.org/10.48550/arXiv.2310.20601)

## Abstract:

Recent theoretical and experimental work in neuroscience has focused on the representational and dynamical character of neural manifolds --subspaces in neural activity space wherein many neurons coactivate. Importantly, neural populations studied under this "neural manifold hypothesis" are continuous and not cleanly divided into separate neural populations. This perspective clashes with the "modular hypothesis" of brain organization, wherein neural elements maintain an "all-or-nothing" affiliation with modules. In line with this modular hypothesis, recent research on recurrent neural networks suggests that multi-task networks become modular across training, such that different modules specialize for task-general dynamical motifs. If the modular hypothesis is true, then it would be important to use a dimensionality reduction technique that captures modular structure. Here, we investigate the features of such a method. We leverage RNNs as a model system to study the character of modular neural populations, using a community detection method from network science known as modularity maximization to partition neurons into distinct modules. These partitions allow us to ask the following question: do these modular boundaries matter to the system?
